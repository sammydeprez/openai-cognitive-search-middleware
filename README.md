# Middleware for Azure Cognitive Search
This middleware is extending the default endpoint of Cognitive Search
Cognitive Search has a feature to extract answers based on semantic reranking BM25. With this middleware the response stays the same but the answer is generated by an Azure Open AI Model.

By using this fuction as a middleware you do not need to change any code in your application when you are already using the semantic answering function.

## Configuration
All needed parameters can be configured as environment variables in the Azure Function Configuration.

|Variable Name|Data Type|Description|
|-------------|---------|-----------|
|**SEARCHSERVICE_NAME**|String|The name of your Cognitive Search resource on Azure|
|**SEARCHSERVICE_SCORE_THRESHOLD**|Decimal|To remove irrelevant content in the context send to OpenAI, the middleware will filter content based on the Semantic Reranking Score. The highest score will be taken and only the results with a higher score then the highest socre * this parameter will be used|
|**SEARCHSERVICE_MAX_NO_RESULTS**|Integer|Number of maximum results that you want to send to OpenAI Completion api|
|**SEARCHSERVICE_FIELD_CONTENT**|String|The field in your index that contains the content that will be send to OpenAI as context|
|**SEARCHSERVICE_FIELD_KEY**|String|The field in your index that contains a unique key to your content, so that depending on your system message the sources can be citated in the answer|
|**OPENAI_API_KEY**|String|API Key to your OpenAI service|
|**OPENAI_API_BASE**|String|API endpoint to your OpenAI service|
|**OPENAI_API_VERSION**|String|API version that you want to use for the OpenAI service|
|**OPENAI_API_TYPE**|String|"azure" for Azure OpenAI or "openai" for the non Azure OpenAI endpoints|
|**OPENAI_API_DEFAULT_MODEL**|String|The default OpenAI model that you want to use, supporting gpt-35-turbo and gpt-4|
|**OPENAI_API_SYSTEM_MESSAGE**|String|System message|
